# LLaVA-NeXT æœå‹™ - å¿«é€Ÿé–‹å§‹æŒ‡å—

æœ¬æŒ‡å—å°‡å¹«æ‚¨åœ¨ 5 åˆ†é˜å…§å•Ÿå‹• LLaVA-NeXT æœå‹™ã€‚

## å‰ç½®è¦æ±‚

- âœ… Docker å’Œ Docker Compose å·²å®‰è£
- âœ… è‡³å°‘ 8GB RAMï¼ˆå»ºè­° 16GBï¼‰
- âœ… è‡³å°‘ 50GB ç£ç¢Ÿç©ºé–“
- âœ… å¯é¸ï¼šNVIDIA GPUï¼ˆåŠ é€ŸæŽ¨ç†ï¼‰

## 1. å…‹éš†æˆ–é€²å…¥æœå‹™ç›®éŒ„

```bash
cd /path/to/llava-next-service
```

## 2. æª¢æŸ¥ Docker ç’°å¢ƒ

```bash
# æª¢æŸ¥ Docker ç‰ˆæœ¬
docker --version

# æª¢æŸ¥ Docker Compose ç‰ˆæœ¬
docker-compose --version
```

## 3. å»ºæ§‹ä¸¦å•Ÿå‹•æœå‹™

```bash
# æ–¹å¼ 1ï¼šä½¿ç”¨ docker-composeï¼ˆæŽ¨è–¦ï¼‰
docker-compose up -d --build

# æ–¹å¼ 2ï¼šä½¿ç”¨ start.sh è…³æœ¬
chmod +x start.sh
./start.sh
```

## 4. æª¢æŸ¥æœå‹™ç‹€æ…‹

```bash
# æª¢æŸ¥å®¹å™¨æ˜¯å¦é‹è¡Œä¸­
docker ps | grep llava-next-service

# æŸ¥çœ‹æ—¥èªŒ
docker logs -f llava-next-service
```

**é æœŸæ—¥èªŒè¼¸å‡ºï¼š**
```
Loading model: llava-hf/llava-v1.6-34b-hf
Device: cuda
Loading LLaVA-NeXT model...
Model loaded successfully!
INFO:     Started server process [1]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000
```

**âš ï¸ æ³¨æ„ï¼š**é¦–æ¬¡å•Ÿå‹•å¯èƒ½éœ€è¦ 10-30 åˆ†é˜ä¸‹è¼‰æ¨¡åž‹ï¼ˆ~70GBï¼‰ï¼Œè«‹è€å¿ƒç­‰å¾…ã€‚

## 5. æ¸¬è©¦æœå‹™

### æ¸¬è©¦å¥åº·æª¢æŸ¥

```bash
curl http://localhost:8001/health
```

**é æœŸå›žæ‡‰ï¼š**
```json
{
  "status": "ok",
  "model": "llava-hf/llava-v1.6-34b-hf",
  "device": "cuda"
}
```

### æ¸¬è©¦ç›®éŒ„è­˜åˆ¥ï¼ˆä½¿ç”¨æ¸¬è©¦è…³æœ¬ï¼‰

```bash
# å‰µå»ºæ¸¬è©¦è…³æœ¬
cat > test_llava.py << 'EOF'
import base64
import json
import requests
from pathlib import Path

# æ¸¬è©¦åœ–ç‰‡è·¯å¾‘ï¼ˆæ›¿æ›ç‚ºæ‚¨çš„ç›®éŒ„é åœ–ç‰‡ï¼‰
IMAGE_PATH = "path/to/toc-page.png"

# è®€å–åœ–ç‰‡ä¸¦è½‰ç‚º base64
with open(IMAGE_PATH, 'rb') as f:
    image_data = base64.b64encode(f.read()).decode('utf-8')

# èª¿ç”¨ API
response = requests.post(
    "http://localhost:8001/recognize-toc",
    json={"image": image_data}
)

print("Status:", response.status_code)
print("Response:", json.dumps(response.json(), indent=2, ensure_ascii=False))
EOF

# é‹è¡Œæ¸¬è©¦
python test_llava.py
```

### æ¸¬è©¦ä½¿ç”¨ curl

```bash
# å‡è¨­æ‚¨æœ‰ä¸€å€‹ base64 ç·¨ç¢¼çš„åœ–ç‰‡
curl -X POST http://localhost:8001/recognize-toc \
  -H "Content-Type: application/json" \
  -d '{
    "image": "base64_encoded_image_string"
  }'
```

## 6. æ•´åˆåˆ° n8n å·¥ä½œæµ

åœ¨ n8n ä¸­å‰µå»º **HTTP Request** ç¯€é»žï¼š

```json
{
  "method": "POST",
  "url": "http://llava-next-service:8001/recognize-toc",
  "headers": {
    "Content-Type": "application/json"
  },
  "body": {
    "image": "{{$json.base64Image}}"
  }
}
```

**n8n å·¥ä½œæµæµç¨‹ï¼š**
1. Webhook ç¯€é»žï¼šæŽ¥æ”¶ PDF æª”æ¡ˆ
2. HTTP Requestï¼šèª¿ç”¨ Docling ç”Ÿæˆç›®éŒ„é åœ–åƒ
3. Code ç¯€é»žï¼šå°‡åœ–ç‰‡è½‰ç‚º base64
4. HTTP Requestï¼šèª¿ç”¨ LLaVA-NeXT Service è­˜åˆ¥ç›®éŒ„
5. Code ç¯€é»žï¼šåˆä½µç›®éŒ„ + Docling Markdown
6. HTTP Requestï¼šä¸Šå‚³åˆ° Supabase

## 7. åœæ­¢æœå‹™

```bash
# åœæ­¢ä¸¦ç§»é™¤å®¹å™¨
docker-compose down

# åœæ­¢ä¸¦ç§»é™¤å®¹å™¨å’Œ volume
docker-compose down -v
```

## 8. æ›´æ–°æœå‹™

```bash
# é‡æ–°å»ºæ§‹ä¸¦å•Ÿå‹•
docker-compose up -d --build --force-recreate
```

## å¸¸è¦‹å•é¡Œ

### Q1: æ¨¡åž‹ä¸‹è¼‰å¤ªæ…¢æ€Žéº¼è¾¦ï¼Ÿ

**A:** é¦–æ¬¡ä¸‹è¼‰æ¨¡åž‹å¯èƒ½éœ€è¦å¾ˆé•·æ™‚é–“ï¼ˆ10-30 åˆ†é˜ï¼‰ã€‚
- æª¢æŸ¥ç¶²é€Ÿ
- è€ƒæ…®ä½¿ç”¨ä»£ç†æˆ– VPN
- è€å¿ƒç­‰å¾…ï¼Œæ—¥èªŒæœƒé¡¯ç¤ºä¸‹è¼‰é€²åº¦

### Q2: æœå‹™å•Ÿå‹•å¤±æ•—

**A:** æª¢æŸ¥æ—¥èªŒï¼š
```bash
docker logs llava-next-service
```

å¸¸è¦‹åŽŸå› ï¼š
- **è¨˜æ†¶é«”ä¸è¶³**ï¼šæ¸›å°‘ Docker memory é™åˆ¶
- **ç£ç¢Ÿç©ºé–“ä¸è¶³**ï¼šé‡‹æ”¾ç©ºé–“
- **ç«¯å£è¢«ä½”ç”¨**ï¼šä¿®æ”¹ docker-compose.yml ä¸­çš„ç«¯å£æ˜ å°„

### Q3: è­˜åˆ¥çµæžœä¸æº–ç¢º

**A:** å˜—è©¦ä»¥ä¸‹æ–¹æ³•ï¼š
1. æé«˜åœ–ç‰‡æ¸…æ™°åº¦
2. èª¿æ•´åœ–ç‰‡å¤§å°ï¼ˆä¸è¦è¶…éŽ 1024x1024ï¼‰
3. ä½¿ç”¨æ›´é«˜åˆ†è¾¨çŽ‡ç‰ˆæœ¬çš„æ¨¡åž‹ï¼ˆLLaVA-NeXT-72Bï¼‰

### Q4: å¦‚ä½•ä½¿ç”¨ GPU åŠ é€Ÿï¼Ÿ

**A:** ä¿®æ”¹ docker-compose.ymlï¼š

```yaml
services:
  llava-next:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

ä¸¦ç¢ºä¿å·²å®‰è£ NVIDIA Container Toolkitã€‚

### Q5: å¦‚ä½•æŸ¥çœ‹æœå‹™æ€§èƒ½ï¼Ÿ

**A:** ä½¿ç”¨ Docker statsï¼š
```bash
docker stats llava-next-service
```

## ä¸‹ä¸€æ­¥

- ðŸ“– é–±è®€ [README.md](README.md) äº†è§£è©³ç´°åŠŸèƒ½
- ðŸ”§ ä¿®æ”¹ [service.py](service.py) è‡ªè¨‚ Prompt
- ðŸš€ æ•´åˆåˆ° n8n å·¥ä½œæµ

## æŠ€è¡“æ”¯æŒ

å¦‚æœ‰å•é¡Œï¼Œè«‹æŸ¥çœ‹æ—¥èªŒï¼š
```bash
docker logs -f llava-next-service
```

æˆ–è¯ç¹«é–‹ç™¼åœ˜éšŠã€‚
